{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_f5u2x9nn6I",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/cornell_tech2.svg\"></left>\n",
    "\n",
    "# Lecture 19: Introduction to LLMs\n",
    "\n",
    "### Applied Machine Learning\n",
    "\n",
    "__Brandon Amos__<br>Cornell Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np; np.set_printoptions(precision=2)\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.figsize'] = [12, 4]\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "device = 'mps'\n",
    "\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preface and disclaimer ⚠\n",
    "\n",
    "+ Language, NLP, LLMs is a huge space. Many great resources out there!\n",
    "+ **This lecture**\n",
    "    1. Tour through my favorite introductory parts from them\n",
    "    2. Some code examples to show how to apply and use <br/>\n",
    "       a) **basic tokenization** and **autoregressive generation**, <br/>\n",
    "       b) **chat templates**, and <br/>\n",
    "       c) **code completion** (fill-in-the-middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformers and language models: ubiquitous\n",
    "\n",
    "<center>\n",
    "<img width='55%' src=\"https://www.comet.com/site/wp-content/uploads/2023/07/Screen-Shot-2023-07-11-at-9.48.50-PM-1536x1153.png\"/><br/>\n",
    "<a href=\"https://www.comet.com/site/blog/explainable-ai-for-transformers/\">Image sources: Explainable AI: Visualizing Attention in Transformers</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review on classification\n",
    "\n",
    "$$ \\underbrace{\\text{Dataset}}_\\text{Features, Attributes, Targets} + \\underbrace{\\text{Learning Algorithm}}_\\text{Model Class + Objective + Optimizer } \\to \\text{Predictive Model} $$\n",
    "\n",
    "-----\n",
    "\n",
    "1. Training dataset $\\mathcal{D} = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\ldots, (x^{(N)}, y^{(N)})\\}$.\n",
    "2. The target space is discrete: $\\mathcal{Y} = \\{y_1, y_2, \\ldots y_K\\}$. <br>\n",
    "   <span style='color: gray'>Each of the $K$ discrete values corresponds to a *class* that we want to predict</span>\n",
    "3. Optimize the conditional likelihood\n",
    "    $$\\max_\\theta \\ell(\\theta) = \\max_{\\theta} \\frac{1}{n}\\sum_{i=1}^N \\log P_\\theta(y^{(i)} | {x}^{(i)}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LLMs (for generation) are \"just\" doing next-token classification\n",
    "\n",
    "+ Represent language as a sequence of **discrete tokens**\n",
    "+ Given the past sequence of text $x^{(i)}$, classify the next portion $y{(i)}$.\n",
    "+ Parameterize $P_\\theta$ with a sequence architecture (e.g., a transformer)\n",
    "+ (Pre)train with maximum likelihood\n",
    "  $$\\max_\\theta \\ell(\\theta) = \\max_{\\theta} \\frac{1}{n}\\sum_{i=1}^N \\log P_\\theta(y^{(i)} | {x}^{(i)}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization and representing language\n",
    "\n",
    "+ **Tokenization** is how the string is represented <span style='color: grey'>(what the $K$ values correspond to)</span>\n",
    "+ Dataset has token strings $x^{(i)}\\in\\{1, \\ldots, K\\}^{n_i}$\n",
    "  and next tokens $y^{(i)}\\in\\{1, \\ldots, K\\}$:\n",
    "  $$\\mathcal{D} = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\ldots, (x^{(N)}, y^{(N)})\\}$$\n",
    "+ Many options for how to tokenize a sequence, e.g.:\n",
    "\n",
    "<center>\n",
    "<img width='25%' src='https://njoroge.tomorrow.co.ke/static/images/AI/tokenization.jpg'/><br/>\n",
    "\n",
    "Image source: \n",
    "<a href=\"https://njoroge.tomorrow.co.ke/blog/ai/word_vs_character_level_tokenization\">Character vs. Word Tokenization in NLP</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization in practice\n",
    "\n",
    "+ A large topic and very important choice\n",
    "+ Tokens often learned via Byte-Pair Encoding, SentencePiece, or WordPiece\n",
    "+ Many other great resources:\n",
    "  + [HuggingFace Tokenizer Summary](https://huggingface.co/docs/transformers/en/tokenizer_summary)\n",
    "  + [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE) ([code](https://github.com/karpathy/minbpe))\n",
    "  + [Llama tokenizer visualizer](https://belladoreai.github.io/llama-tokenizer-js/example-demo/build/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applications of transformers\n",
    "\n",
    "<img src=\"https://www.comet.com/site/wp-content/uploads/2023/07/Screen-Shot-2023-07-13-at-6.37.03-PM.png\"/>\n",
    "<center><a href=\"https://www.comet.com/site/blog/explainable-ai-for-transformers/\">Image source: Explainable AI: Visualizing Attention in Transformers</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What the transformer looks like\n",
    "\n",
    "<center>\n",
    "<img width='55%' src=\"https://sebastianraschka.com/images/blog/2023/self-attention-from-scratch/summary.png\"> <br/>\n",
    "\n",
    "<small><a href=\"https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html\">Source: Understanding and Coding the Self-Attention Mechanism of LLMs From Scratch</a></small>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Putting everything together\n",
    "\n",
    "<center>\n",
    "<img width='70%' src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd8bc0b7-e7b7-4a96-9e00-627ad2ecda20_2232x1362.png\"/> <br>\n",
    "(Source: the Llama 2 paper)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Full architectures\n",
    "\n",
    "Combine many components we've covered: embeddings, attention, residual\n",
    "\n",
    "<center>\n",
    "<img width='60%' src=\"https://media.licdn.com/dms/image/v2/D5612AQGzmd6t0QZpcw/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1710740975319?e=1736985600&v=beta&t=a-hzk4nmEQCMeKYfX7miID0veRX8AwM4Hd6dxF9qPOo\"/> <br/>\n",
    "Image source: <a href=\"https://www.youtube.com/@umarjamilai\">Umar Jamil</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Going deeper into the architecture\n",
    "\n",
    "+ Many other interesting design choices we won't cover, especially positional embeddings, masking, KV caching, flash attention\n",
    "+ Some further reading:\n",
    "    + [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "    + [Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)\n",
    "    + [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "    + [Explained: Multi-head Attention](https://storrs.io/attention/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Going even deeper into the training setup \n",
    "\n",
    "Maximum likelihood (pre)training is just the beginning...\n",
    "+ Alignment, supervised fine-tuning, preference optimization, RLHF, tool use\n",
    "\n",
    "<center>\n",
    "<img width='75%' src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb9d0144-3952-42db-8382-8e2eb37d917e_1670x640.png\">\n",
    "</center>\n",
    "\n",
    "<center>Image source: <a href=\"https://arxiv.org/abs/2203.02155\">InstructGPT</a> (and <a href=\"https://cameronrwolfe.substack.com/p/understanding-and-using-supervised\">here</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/cornell_tech2.svg\"></left>\n",
    "\n",
    "# Part 2: Running some code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loading a model and tokenizer\n",
    "\n",
    "+ [HuggingFace](https://huggingface.co/) hosts many models, tokenizers, datasets, and benchmarks\n",
    "and provides Python/PyTorch libraries for downloading and using them\n",
    "+ Let's load a \"small\" (with 1B parameters) Llama 3.2 model. (It runs on my laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's start with the tokenizer. What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='meta-llama/Llama-3.2-1B-Instruct', vocab_size=128000, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128005: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128011: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128012: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128013: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128014: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128015: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128016: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128017: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128018: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128019: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128020: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128021: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128022: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128023: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128024: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128025: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128026: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128027: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128028: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128029: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128030: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128031: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128032: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128033: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128034: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128035: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128036: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128037: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128038: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128039: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128040: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128041: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128042: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128043: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128044: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128045: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128046: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128047: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128048: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128049: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128050: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128051: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128052: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128053: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128054: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128055: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128056: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128057: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128058: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128059: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128060: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128061: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128062: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128063: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128064: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128065: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128066: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128067: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128068: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128069: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128070: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128071: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128072: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128073: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128074: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128075: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128076: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128077: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128078: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128079: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128080: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128081: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128082: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128083: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128084: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128085: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128086: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128087: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128088: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128089: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128090: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128091: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128092: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128093: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128094: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128095: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128096: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128097: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128098: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128099: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128100: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128101: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128102: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128103: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128104: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128105: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128106: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128107: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128108: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128109: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128110: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128111: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128112: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128113: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128114: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128115: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128116: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128117: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128118: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128119: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128120: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128121: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128122: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128123: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128124: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128125: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128126: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128127: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128128: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128129: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128130: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128131: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128132: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128133: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128134: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128135: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128136: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128137: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128138: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128139: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128140: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128141: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128142: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128143: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128144: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128145: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128146: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128147: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128148: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128149: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128150: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128151: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128152: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128153: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128154: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128155: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128156: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128157: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128158: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128159: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128160: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128161: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128162: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128163: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128164: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128165: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128166: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128167: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128168: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128169: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128170: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128171: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128172: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128173: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128174: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128175: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128176: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128177: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128178: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128179: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128180: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128181: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128182: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128183: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128184: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128185: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128186: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128187: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128188: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128189: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128190: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128191: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128192: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128193: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128194: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128195: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128196: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128197: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128198: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128199: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128200: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128201: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128202: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128203: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128204: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128205: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128206: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128207: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128208: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128209: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128210: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128211: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128212: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128213: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128214: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128215: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128216: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128217: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128218: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128219: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128220: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128221: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128222: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128223: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128224: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128225: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128226: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128227: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128228: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128229: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128230: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128231: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128232: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128233: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128234: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128235: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128236: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128237: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128238: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128239: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128240: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128241: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128242: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128243: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128244: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128245: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128246: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128247: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128248: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128249: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128250: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128251: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128252: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128253: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128254: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128255: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's check the vocabulary\n",
    "<span style='color: grey'>(Ġ is special and indicates the beginning of a word)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eteria': 78922,\n",
       " 'Ġrings': 25562,\n",
       " 'ĠRR': 44498,\n",
       " '.Ticks': 98846,\n",
       " 'Equals': 4413,\n",
       " 'Win': 17400,\n",
       " 'ĠIReadOnly': 83196,\n",
       " 'ardless': 30920,\n",
       " '<bits': 48357,\n",
       " '_PERSON': 74528,\n",
       " 'éħĴ': 103882,\n",
       " '}${': 32292,\n",
       " 'Ġobjc': 64426,\n",
       " 'ĠDown': 6419,\n",
       " 'ĠØ³ÙģØ±': 116149,\n",
       " '-town': 84003,\n",
       " 'áº·p': 105691,\n",
       " '(Msg': 100026,\n",
       " 'Ġupgrading': 47035,\n",
       " '.imag': 72077,\n",
       " 'Ġharvest': 24322,\n",
       " 'Ġpops': 48700,\n",
       " 'ekk': 111784,\n",
       " 'Ġparachute': 99220,\n",
       " '-interest': 65873,\n",
       " 'Craig': 87376,\n",
       " 'grant': 52727,\n",
       " 'WATCH': 65592,\n",
       " 'bots': 63005,\n",
       " 'çĹħéĻ¢': 122412,\n",
       " 'ĠÑģÑħ': 104438,\n",
       " 'Ġpersonals': 48830,\n",
       " \"Ġ'-')\": 70263,\n",
       " 'vtk': 61187,\n",
       " 'ÂłÂłÂł': 46493,\n",
       " 'Pay': 21243,\n",
       " 'Ġlineno': 86195,\n",
       " 'ĠObviously': 36530,\n",
       " 'æłªå¼ıä¼ļç¤¾': 121450,\n",
       " 'arna': 40315,\n",
       " 'Ġwatermark': 89106,\n",
       " 'ìĺĢëĭ¤': 102563,\n",
       " 'ĠÐ¿Ð¾Ð»Ð½Ð¾ÑģÑĤÑĮÑİ': 113674,\n",
       " 'Ð»Ð¸Ðº': 109601,\n",
       " 'ÐºÐ¾Ð¼': 101098,\n",
       " 'Bulletin': 99735,\n",
       " 'ĠMcCabe': 86058,\n",
       " 'Ġfq': 83567,\n",
       " 'Ġssh': 30330,\n",
       " 'Ġstyled': 11343,\n",
       " '$error': 52509,\n",
       " '-Qaeda': 57985,\n",
       " 'Ġreacts': 69945,\n",
       " 'ĠÐľÐ¸Ð½': 123117,\n",
       " 'à¸±à¸ļà¸ľ': 112708,\n",
       " 'ÅĻeba': 106372,\n",
       " 'Ġontvang': 96152,\n",
       " 'Ġparten': 98394,\n",
       " 'Ġjdbc': 87002,\n",
       " 'Ġattenu': 57732,\n",
       " '*=': 41108,\n",
       " 'EventType': 49006,\n",
       " '_rotation': 45913,\n",
       " 'addTo': 51401,\n",
       " 'grand': 53766,\n",
       " 'Ġartwork': 29409,\n",
       " 'Ġclues': 43775,\n",
       " 'ÑĥÑĶÑĤÑĮÑģÑı': 104404,\n",
       " '.DataGridViewCellStyle': 51486,\n",
       " '(units': 84165,\n",
       " 'inae': 125887,\n",
       " 'plot': 4569,\n",
       " \"'],$_\": 98289,\n",
       " \"')}}Ċ\": 83993,\n",
       " '****': 431,\n",
       " 'ãģ£ãģ¡': 120240,\n",
       " 'Ġuncomfortable': 29213,\n",
       " 'med': 2106,\n",
       " 'ĠRaw': 23886,\n",
       " 'Ġgeomet': 69086,\n",
       " 'Ġgobierno': 81893,\n",
       " 'ĠbÃªn': 103381,\n",
       " 'Ġlever': 28605,\n",
       " '656': 20744,\n",
       " 'ĠFurious': 93431,\n",
       " 'ĠOpportunities': 66885,\n",
       " 'ĠIndianapolis': 42451,\n",
       " 'Descripcion': 54855,\n",
       " '$route': 58812,\n",
       " 'Cu': 45919,\n",
       " 'ĠText': 2991,\n",
       " 'ĠfullWidth': 52420,\n",
       " '.loaded': 61979,\n",
       " 'Ġfleet': 26155,\n",
       " '|required': 69688,\n",
       " 'Ð¤': 55258,\n",
       " 'Ġnaj': 30274,\n",
       " 'Ġsuger': 98684,\n",
       " 'messages': 16727,\n",
       " 'dsp': 95824,\n",
       " 'Ġweight': 4785,\n",
       " '.Init': 27947,\n",
       " 'Ġyog': 42453,\n",
       " 'Ø¢ÙħØ¯': 116797,\n",
       " 'ĠSpeak': 68301,\n",
       " 'Ġvnode': 69821,\n",
       " 'ĠtotalCount': 60813,\n",
       " 'à¥īà¤ķ': 107409,\n",
       " 'ĠsystÃ©m': 107425,\n",
       " 'lant': 112916,\n",
       " 'Ġà¹Ģà¸¡': 103455,\n",
       " 'ĠEVERY': 45974,\n",
       " 'ĠFrid': 64104,\n",
       " 'Ð¾Ð²Ñĸ': 104420,\n",
       " 'ÑİÑīÐ¸ÑħÑģÑı': 125967,\n",
       " 'Ø®Ø´': 109174,\n",
       " 'Ġ\".$': 15129,\n",
       " 'Ġozone': 77537,\n",
       " 'Ġpredictive': 60336,\n",
       " 'ĠeSports': 89796,\n",
       " 'à¸¢à¸Ļà¸ķà¸£': 120606,\n",
       " 'Ġr': 436,\n",
       " 'los': 2353,\n",
       " 'Calls': 56392,\n",
       " 'ĠFunctor': 88732,\n",
       " 'ĠÏĦÎ¿Ïħ': 100456,\n",
       " 'ToFit': 74042,\n",
       " '.Al': 9833,\n",
       " 'Ġmiejsc': 92994,\n",
       " '_CHAR': 21561,\n",
       " 'Alabama': 98911,\n",
       " 'ĠNYPD': 74255,\n",
       " 'Ġkeys': 7039,\n",
       " 'Ġvoiced': 52468,\n",
       " '.ascii': 89997,\n",
       " '.validation': 25791,\n",
       " '\"):': 38151,\n",
       " 'animal': 48999,\n",
       " 'ĠMessageType': 63436,\n",
       " 'oria': 11015,\n",
       " 'à¹Ģà¸ķ': 101652,\n",
       " 'Ġnug': 82880,\n",
       " 'Ġonay': 115583,\n",
       " 'ĠTampa': 33225,\n",
       " 'ï¼ĮæĪĳ': 101602,\n",
       " 'âĢĶall': 87247,\n",
       " 'ĠLenovo': 64799,\n",
       " 'Ġfemmes': 31656,\n",
       " 'Ġrapid': 11295,\n",
       " '_INLINE': 33582,\n",
       " '_est': 19095,\n",
       " 'ĠÄįeskÃ©': 119172,\n",
       " 'Ġunsuccessfully': 97725,\n",
       " 'ĠTor': 8611,\n",
       " 'ĠÐ¿Ð¾Ð¶': 107813,\n",
       " 'Ġstring': 925,\n",
       " 'Ġnotify': 15820,\n",
       " 'ĠBrent': 47431,\n",
       " 'ĠPhaser': 64768,\n",
       " 'Ġdrawing': 13633,\n",
       " '(un': 18870,\n",
       " 'ĠÐ¿ÐµÑĢÑģ': 119887,\n",
       " 'Ġpipelines': 58773,\n",
       " 'ĠDiablo': 74337,\n",
       " 'gon': 11932,\n",
       " 'ĠÎ¼ÏĮ': 110701,\n",
       " 'ĠBenghazi': 68868,\n",
       " 'user': 882,\n",
       " 'ĠBrilliant': 94374,\n",
       " 'mongo': 54170,\n",
       " 'ĠFallen': 84088,\n",
       " 'notice': 24467,\n",
       " 'ĠWay': 12424,\n",
       " '(prog': 81178,\n",
       " 'ĠMG': 52292,\n",
       " '**)': 43042,\n",
       " 'ë²Ħ': 80104,\n",
       " 'lient': 1477,\n",
       " '>.ĊĊ': 95467,\n",
       " 'ĠÐ°Ð¼': 123527,\n",
       " '.Quit': 96932,\n",
       " 'Ã¨tre': 99746,\n",
       " ')./': 90586,\n",
       " 'Ġ=>Ċ': 6408,\n",
       " 'Ġnose': 19689,\n",
       " 'ĠLug': 93590,\n",
       " 'Franc': 81428,\n",
       " 'ĉlogrus': 91922,\n",
       " 'Ġpalavra': 95747,\n",
       " '<|begin_of_text|>': 128000,\n",
       " '.ds': 61117,\n",
       " 'interopRequireDefault': 36464,\n",
       " 'Ġbeliever': 62379,\n",
       " 'ĠRisk': 32388,\n",
       " ',readonly': 93009,\n",
       " 'Ġmamma': 90411,\n",
       " 'meet': 64510,\n",
       " 'Ġyear': 1060,\n",
       " 'ĠÐ¿ÑĢÐ¸Ð½Ð¸Ð¼Ð°ÑĤÑĮ': 127246,\n",
       " 'ĠØ´ÙħØ§': 103093,\n",
       " 'iÅ¡': 113970,\n",
       " 'ĠObamacare': 37096,\n",
       " 'ä¸ĭçļĦ': 114972,\n",
       " '.length': 1996,\n",
       " '.pre': 6357,\n",
       " 'chedules': 50713,\n",
       " 'unicip': 13917,\n",
       " 'Ġenvelop': 54285,\n",
       " ',function': 38364,\n",
       " 'ĠOleDb': 57945,\n",
       " 'Sou': 58532,\n",
       " 'Ġnursing': 28456,\n",
       " 'Ġempresa': 33864,\n",
       " 'ÑĥÐ²Ð°Ð»Ð¸ÑģÑı': 126032,\n",
       " 'QueryParam': 85185,\n",
       " 'not': 1962,\n",
       " '>+': 96426,\n",
       " 'Ġsesso': 18750,\n",
       " 'Ġ{_': 49717,\n",
       " 'ĠGuy': 26340,\n",
       " 'âłĢ': 75819,\n",
       " '_STANDARD': 74925,\n",
       " 'MAR': 61761,\n",
       " 'ĠEngl': 99730,\n",
       " 'INATION': 52960,\n",
       " 'ĠMitchell': 31038,\n",
       " 'INSTALL': 62948,\n",
       " 'getCode': 59034,\n",
       " 'enia': 59386,\n",
       " 'SOAP': 83669,\n",
       " '-scripts': 95248,\n",
       " 'ifiÃ©': 90859,\n",
       " 'ĠÎ¤Î¿Ïħ': 126389,\n",
       " 'URT': 88196,\n",
       " 'yellow': 28969,\n",
       " 'Recording': 53956,\n",
       " 'tual': 120895,\n",
       " '_MAP': 16705,\n",
       " 'Gener': 5648,\n",
       " 'Ð¾Ð²Ñĥ': 114176,\n",
       " '.createUser': 87677,\n",
       " 'Ġvalve': 32530,\n",
       " 'LETTE': 86548,\n",
       " 'ÐµÑī': 86610,\n",
       " '/issues': 39845,\n",
       " 'Ġfresh': 7878,\n",
       " 'ĠMature': 43259,\n",
       " '_feedback': 59238,\n",
       " 'Ġpasado': 58516,\n",
       " 'ĠBurg': 41109,\n",
       " 'ĠMartin': 11826,\n",
       " 'ĠØ®Ø±': 104384,\n",
       " 'ĠisError': 88712,\n",
       " '.Measure': 91975,\n",
       " 'ĠÙ¾ÛĮÚ©': 125352,\n",
       " 'PointCloud': 59242,\n",
       " 'ĠleÅ¾ÃŃ': 126170,\n",
       " 'Ġdefaultstate': 55558,\n",
       " '+)\\\\': 80958,\n",
       " 'Ð²Ð¾Ð»': 104341,\n",
       " 'Ġdecreases': 43154,\n",
       " 'Ġperfection': 39143,\n",
       " 'Ġtuáº§n': 111314,\n",
       " 'ĠÙĨØ§Ø¨': 126044,\n",
       " 'Ġê¸Ī': 104193,\n",
       " 'SplitOptions': 77987,\n",
       " 'ĠFebruary': 7552,\n",
       " '/|': 117941,\n",
       " 'ĠÎ±Î½': 101619,\n",
       " 'ÏĥÏĦÏĮ': 110607,\n",
       " 'im': 318,\n",
       " '-password': 34169,\n",
       " 'à¹ĥà¸Ī': 102775,\n",
       " 'æ¨ª': 109203,\n",
       " 'ï¼īčĊ': 92378,\n",
       " 'Ġlat': 6987,\n",
       " 'accessible': 63447,\n",
       " '.bot': 35809,\n",
       " 'Ġjd': 74476,\n",
       " 'Ġpromotion': 20862,\n",
       " 'Ġlaps': 51055,\n",
       " 'ĉassertEquals': 22476,\n",
       " 'ĠAppend': 30907,\n",
       " 'ĠPX': 56584,\n",
       " 'Iran': 62819,\n",
       " 'ĠElectronic': 35269,\n",
       " '.decode': 16301,\n",
       " 'ÃŃl': 103348,\n",
       " '...ĊĊĊ': 52130,\n",
       " 'Ġannoyed': 57130,\n",
       " 'ithe': 83856,\n",
       " 'bb': 6194,\n",
       " 'Ġhepat': 58259,\n",
       " 'Ġpotency': 77229,\n",
       " 'ãĥ¼ãĥ«': 64178,\n",
       " 'ÙĨØ¯Ø±': 114003,\n",
       " 'Ġmimetype': 81108,\n",
       " 'ĠÙĩÙħ': 100550,\n",
       " 'endif': 2384,\n",
       " 'Ġcada': 19394,\n",
       " ']ĊĊĊ': 22414,\n",
       " 'Ġstrugg': 8089,\n",
       " 'acker': 9881,\n",
       " '(Throwable': 62613,\n",
       " 'Ġfre': 3541,\n",
       " 'ÂĢÂĢÂĢÂĢÂĢÂĢÂĢÂĢ': 119751,\n",
       " '(U': 12597,\n",
       " 'Traits': 43920,\n",
       " 'ĠÄ°li': 123382,\n",
       " 'Tek': 56815,\n",
       " 'ĠÐµÐµ': 102549,\n",
       " 'éĩĮ': 70349,\n",
       " 'burst': 58838,\n",
       " '.place': 25463,\n",
       " 'æĹĹ': 110447,\n",
       " 'ĠDeliver': 65752,\n",
       " 'Ġtabla': 41646,\n",
       " '.LAZY': 92338,\n",
       " 'ĠØ¨Ú¯ÛĮØ±': 119414,\n",
       " 'eras': 9431,\n",
       " 'later': 68676,\n",
       " '.schedule': 40953,\n",
       " '_SPI': 32948,\n",
       " 'Ġpharmacies': 77605,\n",
       " 'Ġreckless': 54317,\n",
       " 'ĉdone': 41595,\n",
       " '_pub': 35114,\n",
       " 'Ġcompares': 43565,\n",
       " 'Ġnun': 29195,\n",
       " 'Ġunfore': 96691,\n",
       " '\"=>\"': 21284,\n",
       " \"'}}>Ċ\": 46127,\n",
       " 'Ġfinans': 119974,\n",
       " 'Ġduring': 2391,\n",
       " 'tog': 68273,\n",
       " 'Î¼Î·': 102846,\n",
       " 'ĠJeremiah': 83725,\n",
       " 'ĠmouseY': 69147,\n",
       " 'ĠÐ´ÐµÐ¿': 108336,\n",
       " 'Ø¯Ø«': 125162,\n",
       " 'esini': 102858,\n",
       " 'Ġcameras': 18632,\n",
       " 'Ġë¶ģ': 108772,\n",
       " '.clear': 7578,\n",
       " 'Unix': 56932,\n",
       " 'ĠÏĢÎµÏģÎ¹': 103083,\n",
       " 'Ġcases': 5157,\n",
       " 'Ä±p': 102531,\n",
       " 'ĠWAS': 38876,\n",
       " 'ĠdÅ¯leÅ¾it': 111048,\n",
       " 'Ġfounder': 19533,\n",
       " 'ORT': 2938,\n",
       " 'controls': 29617,\n",
       " 'Ġtar': 12460,\n",
       " 'ĠserÃ£o': 99524,\n",
       " 'ĠHIV': 23495,\n",
       " 'Ġapprox': 10049,\n",
       " 'cor': 6133,\n",
       " 'Ġrecur': 64648,\n",
       " '_mapper': 77764,\n",
       " 'Gets': 50458,\n",
       " 'ä¸»': 36668,\n",
       " 'wallet': 36835,\n",
       " 'å¾®': 50034,\n",
       " '=tk': 64851,\n",
       " \".'),Ċ\": 81381,\n",
       " 'Ġlokale': 94987,\n",
       " 'ikip': 14970,\n",
       " 'pei': 64974,\n",
       " '/wait': 87203,\n",
       " 'ĠCv': 53842,\n",
       " 'ÐłÂµ': 124848,\n",
       " '(viewModel': 71563,\n",
       " 'iddleware': 11864,\n",
       " 'Ġcollaborative': 40806,\n",
       " 'Ġwhilst': 24797,\n",
       " 'Ġcontinuing': 14691,\n",
       " 'ĠGow': 93571,\n",
       " 'wt': 9490,\n",
       " 'ĠContractors': 98893,\n",
       " 'Ġthing': 3245,\n",
       " 'à±': 53898,\n",
       " 'Ġtren': 74700,\n",
       " ':test': 85576,\n",
       " 'ĠÙĬÙĪÙħ': 108628,\n",
       " 'createElement': 59108,\n",
       " 'å¸®åĬ©': 123725,\n",
       " 'Ġfavorable': 37849,\n",
       " 'ifying': 7922,\n",
       " 'fib': 76426,\n",
       " 'Ġsideline': 80053,\n",
       " 'yor': 48320,\n",
       " 'ĠTráº§n': 114184,\n",
       " 'ĠTing': 99632,\n",
       " 'Pour': 43278,\n",
       " 'Ġ\\\\\"': 7393,\n",
       " '.preventDefault': 12469,\n",
       " '762': 24376,\n",
       " 'Ġ................': 90014,\n",
       " '/************************': 63722,\n",
       " 'ĠEDIT': 33357,\n",
       " 'ĠCONSTRAINT': 94863,\n",
       " 'Matthew': 50988,\n",
       " 'ĠRomanian': 74697,\n",
       " 'AE': 13983,\n",
       " 'star': 12134,\n",
       " 'Ġremodeling': 70430,\n",
       " '(Message': 30459,\n",
       " '/></': 67438,\n",
       " '.entities': 26624,\n",
       " 'ornings': 52785,\n",
       " 'Ġbothers': 82454,\n",
       " 'rna': 90331,\n",
       " 'ĠÐ½Ð°Ð¹Ð±': 110824,\n",
       " 'ÙĬØ¹': 102303,\n",
       " '$a': 40662,\n",
       " 'ĠBoo': 74784,\n",
       " 'ĠEste': 39776,\n",
       " 'Ġnotified': 30316,\n",
       " '_FRAME': 23056,\n",
       " 'maze': 99050,\n",
       " 'ĠìĦľë¹ĦìĬ¤': 110514,\n",
       " 'ĠSap': 81275,\n",
       " 'agoon': 68513,\n",
       " '(calc': 92730,\n",
       " 'Ġinds': 99613,\n",
       " 'Ġlocked': 16447,\n",
       " 'Ġiframe': 49513,\n",
       " 'ÐºÑĥÐ»ÑĮ': 116925,\n",
       " '_reply': 15683,\n",
       " 'Ġstoryline': 51728,\n",
       " '(pm': 79877,\n",
       " 'Ġprostitutas': 21225,\n",
       " '_For': 85468,\n",
       " 'åĲĪä½ľ': 112355,\n",
       " 'ĠSTL': 70949,\n",
       " '.movies': 77226,\n",
       " '(ByVal': 24437,\n",
       " '_charset': 66983,\n",
       " 'ĠDamn': 83515,\n",
       " 'ĠÑĩÐµÐ»Ð¾Ð²ÐµÑĩÐµÑģ': 127945,\n",
       " 'ient': 1188,\n",
       " ',application': 99713,\n",
       " 'Ġincorrect': 15465,\n",
       " 'ĠJudaism': 64283,\n",
       " '&r': 61717,\n",
       " 'ĠDEALINGS': 29570,\n",
       " 'ĉdate': 45186,\n",
       " 'Ġonslaught': 88792,\n",
       " 'filePath': 37797,\n",
       " 'hibition': 60073,\n",
       " 'ERV': 60429,\n",
       " 'Database': 6116,\n",
       " 'Toggle': 19431,\n",
       " 'Ġtipped': 66472,\n",
       " 'European': 64469,\n",
       " 'ĠEFFECT': 63153,\n",
       " 'Ġapproached': 25735,\n",
       " 'Ġâĸ¼': 114207,\n",
       " 'ĠPY': 43860,\n",
       " 'ĠIndices': 86869,\n",
       " 'ĠCompletely': 86214,\n",
       " 'ãģ§ãģįãģ¾ãģĻ': 125545,\n",
       " 'larÄ±n': 96548,\n",
       " 'ĠAlgeria': 81341,\n",
       " '(Dictionary': 81445,\n",
       " 'ĠDecom': 97478,\n",
       " 'ĠsÄĥ': 30094,\n",
       " 'ennen': 41293,\n",
       " 'ĠØ¯ÙĪØ±Ø¨ÛĮÙĨ': 125678,\n",
       " 'Candidate': 65001,\n",
       " 'Ġãĥ©': 109240,\n",
       " 'agnet': 64333,\n",
       " 'Ġexpired': 27489,\n",
       " 'ëĦĪ': 105078,\n",
       " 'Ġorth': 30299,\n",
       " 'Ð¶Ð½Ð¾': 126770,\n",
       " 'ĠtÃ©to': 106328,\n",
       " 'fires': 56171,\n",
       " 'Ġhappier': 44467,\n",
       " 'Ġnurture': 79530,\n",
       " 'ĠØ§Ø¬Ø§Ø²Ùĩ': 126606,\n",
       " 'Ġotro': 39192,\n",
       " 'Ġterrified': 53731,\n",
       " '.start': 5069,\n",
       " '_player': 15892,\n",
       " 'Ð½Ñİ': 101644,\n",
       " 'ĉStringBuilder': 51496,\n",
       " 'ĠPadding': 23889,\n",
       " 'ĠØ®ÙĪÙĨ': 119176,\n",
       " 'PLL': 63255,\n",
       " 'Ø®Ø±ÛĮØ¯': 121817,\n",
       " '(shader': 55697,\n",
       " '_hr': 71238,\n",
       " 'Ġamongst': 24059,\n",
       " 'Ġheel': 35428,\n",
       " 'Ġbesonders': 76690,\n",
       " 'ĠChoi': 87673,\n",
       " '_OD': 61526,\n",
       " '.getEnd': 97214,\n",
       " 'ĠDefaultValue': 98880,\n",
       " 'Ġseb': 103382,\n",
       " 'Drink': 86037,\n",
       " 'Ġconvenience': 19679,\n",
       " 'ĠExpanded': 40337,\n",
       " 'Ġapologies': 73273,\n",
       " 'ĠYankees': 45383,\n",
       " '_patches': 99619,\n",
       " '.me': 17777,\n",
       " 'ĠBenefits': 39195,\n",
       " 'Ġtyto': 112348,\n",
       " '-marker': 70928,\n",
       " '_BIN': 56820,\n",
       " 'Ġloa': 127513,\n",
       " 'é»Ħ': 105310,\n",
       " 'orraine': 91122,\n",
       " '.panelControl': 83949,\n",
       " 'Å¡tÄĽ': 100913,\n",
       " 'dhcp': 97320,\n",
       " 'ecd': 38306,\n",
       " '.hash': 15452,\n",
       " 'YYYY': 29289,\n",
       " 'Ġrunnable': 79779,\n",
       " 'ONTAL': 37949,\n",
       " '.callbacks': 72134,\n",
       " 'ĠÙĩØ§ÛĮ': 100710,\n",
       " 'ĠTEntity': 91900,\n",
       " 'tooltip': 22263,\n",
       " 'ĠnhiÃªn': 102536,\n",
       " '.jpa': 37804,\n",
       " 'ĠÐ·Ð¾ÐºÑĢÐµÐ¼Ð°': 119472,\n",
       " 'Ð½Ñĥ': 100326,\n",
       " 'Ġreflections': 63851,\n",
       " '(role': 36998,\n",
       " 'Ġexamines': 49095,\n",
       " '/k': 14441,\n",
       " 'aed': 62554,\n",
       " 'ĠReferentialAction': 59870,\n",
       " 'ĠCheng': 57807,\n",
       " 'ãģģ': 108861,\n",
       " ']': 60,\n",
       " 'vasion': 59093,\n",
       " 'ĠìĶ¨': 117264,\n",
       " 'Ġreferences': 15407,\n",
       " '.h': 870,\n",
       " 'èĢ³': 108870,\n",
       " 'Ġcups': 26446,\n",
       " '.cornerRadius': 43107,\n",
       " '.Pay': 96505,\n",
       " '.None': 18982,\n",
       " '_mgmt': 97114,\n",
       " 'âĺĨ': 47238,\n",
       " 'Ġdefenders': 41131,\n",
       " '/ĊĊ': 8851,\n",
       " '];//': 56782,\n",
       " 'idl': 56564,\n",
       " 'ÙħØ¯Ø©': 122253,\n",
       " '_INST': 50993,\n",
       " 'ĠHag': 67639,\n",
       " '-ind': 18251,\n",
       " 'rones': 32921,\n",
       " 'loo': 48233,\n",
       " 'ĠÙħÛĮÚ©ÙĨ': 119378,\n",
       " 'Ġcerr': 27976,\n",
       " 'Ġsubstit': 32434,\n",
       " 'ã': 159,\n",
       " 'ĠPeterson': 40891,\n",
       " 'ĠdÃ¼': 52119,\n",
       " 'Ġconvertible': 68713,\n",
       " '.btnSave': 63480,\n",
       " 'ĉprivate': 2514,\n",
       " 'Monthly': 73107,\n",
       " '_revision': 60956,\n",
       " 'Ġwie': 13672,\n",
       " 'ĠsÃ¢u': 111202,\n",
       " \"('?\": 75645,\n",
       " 'ĠMOR': 72413,\n",
       " 'æ±ł': 107980,\n",
       " 'Ġsubsidized': 95114,\n",
       " '_COOKIE': 77649,\n",
       " 'ĠVers': 25187,\n",
       " 'Ġexcav': 45215,\n",
       " 'ronym': 47980,\n",
       " 'Ð»ÑıÐ½': 108288,\n",
       " '.opts': 57122,\n",
       " 'Dock': 42568,\n",
       " 'ĠtÃŃtulo': 86051,\n",
       " '_am': 23729,\n",
       " '/****************************************************************': 20766,\n",
       " 'stitial': 49270,\n",
       " 'ISTRY': 63149,\n",
       " 'à¹īà¸Ńà¸ĩà¸ŀ': 111467,\n",
       " 'Ġbeef': 25309,\n",
       " 'ĠÄĳá»Ļt': 119949,\n",
       " 'ĠØ³ÛĮØ³ØªÙħ': 109166,\n",
       " 'ParallelGroup': 18927,\n",
       " 'iedad': 40129,\n",
       " 'ãģ¸': 102416,\n",
       " 'ACCESS': 56849,\n",
       " 'ĠSync': 30037,\n",
       " 'ĠrÃ©s': 31807,\n",
       " 'ĠpageCount': 86851,\n",
       " 'ĠÐ¿Ð»Ñİ': 125106,\n",
       " '.Title': 23825,\n",
       " 'ĠCabr': 99894,\n",
       " 'consistent': 79499,\n",
       " 'Ġsudah': 50896,\n",
       " 'fails': 60731,\n",
       " 'ĠphÃŃ': 102262,\n",
       " '\\'>\"': 35538,\n",
       " 'afd': 93239,\n",
       " 'ĠStudies': 19241,\n",
       " 'xDE': 80079,\n",
       " 'Ð²Ð°ÑİÑĤÑģÑı': 125120,\n",
       " 'Ġ*,Ċ': 75892,\n",
       " 'Ġadditions': 38314,\n",
       " 'geries': 61488,\n",
       " 'Ġintegers': 26864,\n",
       " '(scanner': 87091,\n",
       " '_rsa': 83622,\n",
       " 'toolbar': 38630,\n",
       " 'Ġimpr': 23356,\n",
       " 'ĠraÄŁmen': 110337,\n",
       " 'ĠÎ´Î¹': 105160,\n",
       " 'çĳ': 103885,\n",
       " 'Ã¼l': 36624,\n",
       " '_IMPORTED': 26334,\n",
       " '_PM': 41018,\n",
       " 'fdf': 81683,\n",
       " 'ĠInkWell': 85940,\n",
       " 'Ġln': 30490,\n",
       " 'July': 29527,\n",
       " 'zens': 19059,\n",
       " 'Ġglad': 16089,\n",
       " 'ĠéĿ¢': 112972,\n",
       " 'Ġìĺ¬ëĿ¼': 121250,\n",
       " 'ĠØªØ±Ùĥ': 121759,\n",
       " ',ev': 82692,\n",
       " 'mult': 26961,\n",
       " 'Acceleration': 97760,\n",
       " '.an': 10985,\n",
       " 'itud': 13138,\n",
       " 'ĠRegular': 29900,\n",
       " 'Ġstanice': 125327,\n",
       " '\\\\Event': 48129,\n",
       " 'ĠISI': 78301,\n",
       " 'ä¼ĺåĬ¿': 120711,\n",
       " 'cripts': 25207,\n",
       " '(result': 4556,\n",
       " '_par': 23483,\n",
       " 'ĉlines': 79490,\n",
       " 'ĠUserControl': 73765,\n",
       " 'Ġduke': 96923,\n",
       " '?;Ċ': 38545,\n",
       " 'ÑģÑĤÑĢÐ¾Ð²': 120062,\n",
       " 'ĠyaÅŁlÄ±': 126160,\n",
       " '_secret': 22729,\n",
       " 'Ġsails': 86105,\n",
       " '=email': 77471,\n",
       " 'undos': 65954,\n",
       " 'ĠtakÄ±m': 109651,\n",
       " 'ĠÐ³ÐµÐ½ÐµÑĢÐ°': 116595,\n",
       " '(prompt': 73353,\n",
       " 'Cro': 96141,\n",
       " 'Ġjuin': 85859,\n",
       " 'Ġdank': 81222,\n",
       " 'ĠrahatsÄ±z': 121035,\n",
       " 'bcrypt': 66598,\n",
       " '(reverse': 48235,\n",
       " 'Ġdissertation': 37445,\n",
       " 'ologue': 77828,\n",
       " 'ĠÏīÏĤ': 106801,\n",
       " '.anim': 38636,\n",
       " 'Ġà¤Ĩà¤¦': 105045,\n",
       " 'Spl': 95259,\n",
       " 'ĠSupplement': 43491,\n",
       " 'Ġartworks': 97549,\n",
       " 'reme': 9831,\n",
       " 'ĠØ³Ø±Ùħ': 110415,\n",
       " 'Ø®ØªÙĩ': 122207,\n",
       " 'ĠKING': 74911,\n",
       " 'ï¼Įä¸įè¿ĩ': 120395,\n",
       " 'mix': 36171,\n",
       " 'icl': 88467,\n",
       " 'Ġifade': 108524,\n",
       " 'ÄįnÃ©': 109233,\n",
       " 'Ġjos': 88986,\n",
       " 'à¸Łà¸£': 106466,\n",
       " '.ot': 80461,\n",
       " 'Ġprevent': 5471,\n",
       " 'webElementXpaths': 47073,\n",
       " 'ĠMeal': 57488,\n",
       " 'Ġmaintenance': 13709,\n",
       " '_tokenize': 87608,\n",
       " 'Ġreceber': 91245,\n",
       " 'psz': 45788,\n",
       " 'orative': 63465,\n",
       " 'NUM': 17946,\n",
       " 'Ġsupposedly': 33828,\n",
       " '.Fetch': 79606,\n",
       " 'Ġaffirmation': 96963,\n",
       " 'Ġpodcasts': 55346,\n",
       " '/firebase': 67856,\n",
       " 'Ġbargain': 45663,\n",
       " 'Ġzosta': 62975,\n",
       " 'ê·¼': 104152,\n",
       " 'à¹īà¸Ńà¸¡': 81714,\n",
       " 'Ġquelque': 79071,\n",
       " 'ĠYar': 113381,\n",
       " 'Ġmalfunction': 72287,\n",
       " '-track': 54566,\n",
       " 'Ġëĭ´': 110038,\n",
       " 'Ġgroot': 82567,\n",
       " 'Ġshalt': 89635,\n",
       " '.re': 1351,\n",
       " 'Î¼ÎµÏģ': 108836,\n",
       " 'Ġcried': 39169,\n",
       " 'istributor': 79488,\n",
       " 'estre': 73875,\n",
       " '.XtraReports': 37616,\n",
       " 'ãĢĭçļĦ': 127220,\n",
       " 'Ġpatriarch': 71321,\n",
       " 'ï¼īĊĊ': 28966,\n",
       " 'Ġknots': 61317,\n",
       " '=\"--': 99398,\n",
       " '.hist': 67500,\n",
       " '/*': 1075,\n",
       " 'Ġnegot': 11903,\n",
       " 'decision': 65038,\n",
       " 'ĠDeploy': 71695,\n",
       " 'Ġpues': 69610,\n",
       " 'Ġsalon': 40828,\n",
       " 'ĠUnidos': 69519,\n",
       " 'ĠÐ¸Ð»Ð¸': 46177,\n",
       " 'ĠÐ¿Ð¾Ð²ÑĢÐµÐ¶Ð´': 119096,\n",
       " 'à¸Ńà¸°à¹Ħà¸£': 120165,\n",
       " 'Ġverifica': 92171,\n",
       " 'Ġsimilarity': 38723,\n",
       " 'alam': 17243,\n",
       " 'Ð¼Ð¸Ð½': 115275,\n",
       " 'Ġmartin': 96016,\n",
       " 'IP': 3378,\n",
       " 'ĠAuss': 51344,\n",
       " '.FileNotFoundException': 62649,\n",
       " 'Ŀi': 100646,\n",
       " 'à¸±à¸Ľà¸Ķà¸²à¸«': 125618,\n",
       " 'Ġintermediate': 29539,\n",
       " '123': 4513,\n",
       " 'assin': 44823,\n",
       " 'ĠEver': 18374,\n",
       " '=$(\"#': 80983,\n",
       " '>': 29,\n",
       " 'Ġvr': 37200,\n",
       " 'ĠLucia': 80274,\n",
       " '.Decode': 57472,\n",
       " 'à¥Īà¤ª': 119112,\n",
       " 'Ġbreakpoints': 92630,\n",
       " '_ARRAY': 18194,\n",
       " 'chalk': 87488,\n",
       " 'Ġvamp': 60155,\n",
       " 'Depart': 50041,\n",
       " '_met': 45617,\n",
       " '.callback': 28763,\n",
       " 'á»§ng': 114884,\n",
       " 'Uvs': 91191,\n",
       " 'ril': 31660,\n",
       " 'ĠëĮĢ': 62060,\n",
       " '_combo': 55881,\n",
       " 'WHITE': 58099,\n",
       " 'Ġfroze': 90109,\n",
       " 'Disposable': 58712,\n",
       " '-Life': 88908,\n",
       " 'Ãªte': 37093,\n",
       " '.Butter': 98472,\n",
       " 'ĠIvanka': 83432,\n",
       " 'prom': 25475,\n",
       " 'ĠÐ¾ÐºÐ¾Ð½Ñĩ': 120129,\n",
       " 'ĠwhiteColor': 46381,\n",
       " 'issenschaft': 80848,\n",
       " 'ĠISSN': 87786,\n",
       " 'ÑĪÐ°Ñı': 114505,\n",
       " 'ĠÐ´ÐµÑĢÐµÐ²ÑıÐ½': 122721,\n",
       " 'PI': 1932,\n",
       " 'ĠUsers': 14969,\n",
       " '\"So': 48058,\n",
       " 'à¸Ľ': 55784,\n",
       " 'ĠÚ©ÙĨØªØ±ÙĦ': 115037,\n",
       " 'evÅ¡ÃŃm': 110458,\n",
       " 'ÛĮÙĨÙĩ': 103029,\n",
       " 'shuffle': 66455,\n",
       " 'Ġ/.': 15093,\n",
       " 'ismic': 55194,\n",
       " 'aviolet': 85311,\n",
       " 'ĠEmotional': 95300,\n",
       " 'Ġtgt': 51575,\n",
       " 'ĠØ§Ø¨Ø²Ø§Ø±': 122112,\n",
       " '\"What': 31437,\n",
       " \"!');Ċ\": 26570,\n",
       " 'Leaf': 32561,\n",
       " 'Ġlies': 15812,\n",
       " '.DataGridViewContentAlignment': 95656,\n",
       " 'ĠbackgroundImage': 68129,\n",
       " \"'Ä±\": 120057,\n",
       " 'ĠÙ¾Ø§ÙĪØ±Ù¾ÙĪÛĮÙĨØª': 115510,\n",
       " 'Ġdbo': 56959,\n",
       " 'ĨĴ': 101445,\n",
       " 'Ġpurely': 32227,\n",
       " 'Material': 13721,\n",
       " 'ĉbyte': 32522,\n",
       " 'elmet': 75872,\n",
       " 'Ġmediante': 66673,\n",
       " 'Ġsollen': 82246,\n",
       " 'iÄįka': 122313,\n",
       " 'Ø§ÛĮØ´': 102016,\n",
       " 'ĠÑĤÑĢÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñı': 121156,\n",
       " 'ĠHtml': 19751,\n",
       " 'ìĬ¤íħĮ': 127846,\n",
       " 'ĠsluÅ¾eb': 112528,\n",
       " 'ĠÐ½ÐµÐ¾Ð±ÑħÑĸÐ´Ð½Ð¾': 115764,\n",
       " '.spec': 29426,\n",
       " '.SUB': 82851,\n",
       " 'Ġconclusion': 17102,\n",
       " 'çľģ': 66870,\n",
       " 'Ð·Ð²Ð¸ÑĩÐ°Ð¹': 117179,\n",
       " 'Ġrecon': 16456,\n",
       " 'irty': 16938,\n",
       " '_primitive': 85187,\n",
       " 'Ġtechnique': 15105,\n",
       " 'lech': 109902,\n",
       " 'Ġmanager': 6783,\n",
       " 'Ġvibes': 90949,\n",
       " 'Ġfinanzi': 88978,\n",
       " 'ĠìĿ´ëıĻíķ©ëĭĪëĭ¤': 102784,\n",
       " 'Ġdefeated': 24164,\n",
       " 'à¸±à¸ĩ': 100535,\n",
       " 'aar': 74709,\n",
       " 'ÐµÑİ': 114036,\n",
       " 'ĠPublishers': 72714,\n",
       " '.pkl': 50578,\n",
       " '(do': 67505,\n",
       " 'ĠÐ¿ÑĢÐ¾ÑĨÐµÐ´': 108722,\n",
       " '.ExecuteScalar': 82669,\n",
       " 'Ġcolore': 79887,\n",
       " 'ĠschÃ¶': 59559,\n",
       " '-thumb': 67296,\n",
       " 'ĠGro': 18370,\n",
       " \";');Ċ\": 96774,\n",
       " 'Ġknees': 31624,\n",
       " '&C': 70881,\n",
       " 'Ġstimulate': 51077,\n",
       " ':)': 29589,\n",
       " 'Ġsqueezed': 65262,\n",
       " 'rought': 6478,\n",
       " '563': 21789,\n",
       " 'ĠØŃØ³Ø¨': 117459,\n",
       " 'ĠLabour': 18993,\n",
       " 'Ġsued': 42184,\n",
       " '.Selection': 31921,\n",
       " '.glob': 45471,\n",
       " 'ĠzÃ¡kaz': 113646,\n",
       " 'ĠGlover': 95183,\n",
       " 'Ġhitters': 81133,\n",
       " 'é¾Ħ': 120144,\n",
       " '(normal': 53180,\n",
       " '.std': 13392,\n",
       " 'OLLOW': 31289,\n",
       " 'xygen': 19472,\n",
       " 'riz': 25772,\n",
       " 'ischer': 33808,\n",
       " 'ATORS': 61445,\n",
       " 'ãĤĴä½¿': 124905,\n",
       " 'ĠÐ¾ÑĢÐ³Ð°Ð½ÑĸÐ·Ð°ÑĨÑĸÑĹ': 115925,\n",
       " 'straint': 4759,\n",
       " 'ĠopenFileDialog': 98471,\n",
       " '----------</': 49094,\n",
       " 'ĠLore': 54333,\n",
       " '/cmd': 84133,\n",
       " 'Ġflow': 6530,\n",
       " '_mut': 30623,\n",
       " '(y': 7166,\n",
       " 'Ġexamination': 24481,\n",
       " 'Ġmenstr': 54630,\n",
       " 'ĠteÅ¼': 66920,\n",
       " 'ĠÃŃch': 108812,\n",
       " 'ÂłÂłĊ': 122019,\n",
       " 'ĠØ¨Ú¯': 106855,\n",
       " '.strings': 98049,\n",
       " 'll': 657,\n",
       " 'Ã³digo': 33843,\n",
       " 'Ġwszyst': 45927,\n",
       " '])čĊ': 15364,\n",
       " 'ãĢĢĊ': 120582,\n",
       " '.decor': 38512,\n",
       " 'ë¥': 16306,\n",
       " 'asier': 77783,\n",
       " '_py': 41391,\n",
       " 'ooke': 86558,\n",
       " 'ĠØ§ÛĮÙĨØ¬Ø§': 123419,\n",
       " 'Ġìĩ¼': 121346,\n",
       " 'ĠCountdown': 87486,\n",
       " 'PathParam': 94592,\n",
       " 'leich': 55471,\n",
       " 'Ġcake': 19692,\n",
       " '.AUTH': 65778,\n",
       " 'ĠNetworking': 60563,\n",
       " '.nih': 70521,\n",
       " 'Iraq': 97818,\n",
       " 'åħ¬å¼ı': 119695,\n",
       " 'ĠLam': 33794,\n",
       " 'Ġalarms': 63411,\n",
       " 'ÎĹ': 100573,\n",
       " 'Ġretention': 38231,\n",
       " 'Registration': 24253,\n",
       " 'ĠkeyValue': 65037,\n",
       " 'imize': 12117,\n",
       " 'ĉsearch': 46673,\n",
       " 'articles': 16641,\n",
       " '(hand': 64311,\n",
       " 'ĠRJ': 77404,\n",
       " 'ãĥ¢': 102494,\n",
       " 'ĠìĪĺê°Ģ': 127657,\n",
       " 'ãĤ·ãĥ£ãĥ«': 123618,\n",
       " 'Ġjugador': 72776,\n",
       " 'vector': 3295,\n",
       " 'à¹īà¸Ńà¸Ļ': 107987,\n",
       " 'Ġpalette': 27404,\n",
       " 'Ġãģĭ': 119653,\n",
       " 'succ': 65541,\n",
       " 'Ġì¡¸': 116854,\n",
       " 'ÐµÑĤÑĭ': 106141,\n",
       " 'Ġindiscrim': 94546,\n",
       " 'Ġinfiltr': 43364,\n",
       " '_CENTER': 35655,\n",
       " '_POLL': 77920,\n",
       " 'Î³ÏīÎ½': 117112,\n",
       " 'çĿ': 84949,\n",
       " 'ĠÙħÙĩØ±': 111225,\n",
       " '.center': 13729,\n",
       " 'Ġhurry': 48335,\n",
       " 'arrant': 6736,\n",
       " 'drs': 94346,\n",
       " '_payments': 92357,\n",
       " 'ĠCOOKIE': 42665,\n",
       " 'ĠKylie': 98264,\n",
       " '/Math': 99817,\n",
       " 'Ġduplicated': 56003,\n",
       " 'à¸Ľà¸£à¸°à¸Īà¸³': 116417,\n",
       " 'Ġhelping': 10695,\n",
       " 'ĠHarper': 33107,\n",
       " '.marker': 66067,\n",
       " 'respect': 45734,\n",
       " 'å¤īãĤı': 124500,\n",
       " 'ëŁ¬ë¦¬': 127595,\n",
       " 'Ġ\"../': 7150,\n",
       " '(G': 6838,\n",
       " 'ĠFischer': 63016,\n",
       " 'Ġ?>;Ċ': 99287,\n",
       " 'Ġfrankly': 42762,\n",
       " 'Ey': 98554,\n",
       " 'ĠJoey': 55835,\n",
       " '_ctx': 15498,\n",
       " '(___': 95853,\n",
       " 'iales': 33888,\n",
       " 'æŃ¯': 127480,\n",
       " 'ĠglGetUniformLocation': 93820,\n",
       " '[prop': 49915,\n",
       " '.Cast': 66339,\n",
       " 'NullPointerException': 84933,\n",
       " 'ĠÙħØ§ÙĬÙĪ': 119304,\n",
       " '-largest': 68067,\n",
       " 'pert': 77468,\n",
       " ')-': 7435,\n",
       " '>/<': 68872,\n",
       " 'à¹ģà¸ŀ': 109932,\n",
       " 'emodel': 96748,\n",
       " 'ĠÐ¿ÑĢÐ¾Ð¼Ð¸ÑģÐ»Ð¾Ð²': 124331,\n",
       " '#ad': 68968,\n",
       " 'Widgets': 21570,\n",
       " 'oulouse': 67730,\n",
       " 'ç»ĵ': 37985,\n",
       " 'ecer': 94218,\n",
       " 'ĉScanner': 58381,\n",
       " 'ĠsvÃ½m': 113036,\n",
       " '_abs': 32270,\n",
       " 'AttributeName': 51601,\n",
       " 'Ġ//čĊ': 25250,\n",
       " 'Ġamenities': 36483,\n",
       " 'klady': 115828,\n",
       " 'lost': 55437,\n",
       " 'ĠCertificate': 32502,\n",
       " 'gments': 27231,\n",
       " 'pst': 89895,\n",
       " 'EDI': 23988,\n",
       " 'OTA': 37644,\n",
       " 'sse': 65613,\n",
       " '_values': 9324,\n",
       " 'ĠLantern': 68592,\n",
       " 'Ġbáº£o': 101677,\n",
       " 'Cases': 38402,\n",
       " 'ĠIntegral': 92760,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The vocabulary maps subwords to integers <span style='color: grey'>(here, out of 128k possibilities)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6151"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['hi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Encoding** is the process of obtaining the sequence of tokens<br/>\n",
    "<span style='color:grey'>(<a href=\"https://belladoreai.github.io/llama-tokenizer-js/example-demo/build/\">llama-tokenizer.js</a> is great for visualizing this)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5963, 2065, 3187, 925]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_string = tokenizer.encode('tokenization example string', add_special_tokens=False)\n",
    "encoded_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoding** is the process of obtaining the string from tokens<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', 'ization', 'Ġexample', 'Ġstring']\n",
      "tokenization example string\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoded_string))\n",
    "print(tokenizer.decode(encoded_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, let's look at the model. It mostly has components we've seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Querying for generations\n",
    "\n",
    "+ Given the tokenizer and model, and input token sequence $x_{1:n}=[x_1, \\ldots, x_n]$,\n",
    "we can ask the model to predict (generate) next tokens $P(x_{n+j}|x_{1:n+j-1})$.\n",
    "+ The model can sample from many possible generations <br/>\n",
    "  <span style='color: grey'>(often controlled by `temperature`, as well as top-$p$ and top-$k$ parameters)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Once upon a time, in a world where people could talk to their\n",
      "<|begin_of_text|>Once upon a time, in a bustling metropolis, there was a\n",
      "<|begin_of_text|>Once upon a time, in a mystical forest, there lived a young\n",
      "<|begin_of_text|>Once upon a time, there was a young woman named Sophia. Sophia\n",
      "<|begin_of_text|>Once upon a time, in a small village nestled in the rolling hills\n",
      "<|begin_of_text|>Once upon a time, in a world where magic was real, a\n",
      "<|begin_of_text|>Once upon a time, there was a small town where everyone knew each\n",
      "<|begin_of_text|>Once upon a time, there was a small town where everyone knew everyone\n",
      "<|begin_of_text|>Once upon a time, in a bustling city, there was a small\n",
      "<|begin_of_text|>Once upon a time, there was a small, family-owned bakery in\n"
     ]
    }
   ],
   "source": [
    "prompt_str = 'Once upon a time'\n",
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "\n",
    "num_samples = 10\n",
    "outputs = []\n",
    "for _ in range(num_samples):\n",
    "    model_output_tokens = model.generate(\n",
    "        prompt_tokens, do_sample=True, temperature=1.0, max_new_tokens=10,\n",
    "        pad_token_id=tokenizer.eos_token_id, \n",
    "        attention_mask = torch.ones_like(prompt_tokens),\n",
    "    ).squeeze(0)\n",
    "    model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "    outputs.append(model_output_str)\n",
    "\n",
    "for output in outputs:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generations for answering questions\n",
    "\n",
    "With the ability to predict next tokens, we can query the model to answer questions.\n",
    "This is an example from the standard [MMLU benchmark](https://huggingface.co/datasets/cais/mmlu)\n",
    "along with a basic prompt style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
    "\n",
    "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
    "\n",
    "A: Aristotle\n",
    "B: John Locke\n",
    "C: Socrates\n",
    "D: Plato\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
      "\n",
      "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
      "\n",
      "A: Aristotle\n",
      "B: John Locke\n",
      "C: Socrates\n",
      "D: Plato\n",
      "\n",
      "Answer: C\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "\n",
    "model_output_tokens = model.generate(\n",
    "    prompt_tokens, do_sample=False, temperature=None, max_new_tokens=1,\n",
    "    pad_token_id=tokenizer.eos_token_id, attention_mask=torch.ones_like(prompt_tokens)\n",
    ").squeeze(0)\n",
    "model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "print(model_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extracting more information\n",
    "\n",
    "+ The model's generation was correct, but doesn't tell us much\n",
    "+ **Chain-of-thought** prompting is a way of extracting more information,\n",
    "  as done in <a href=\"https://arxiv.org/abs/2205.11916\">Large Language Models are Zero-Shot Reasoners</a>.\n",
    "+ Many variations on this:\n",
    "\n",
    "<center>\n",
    "<img width='70%' src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0EFaLY_NIIDkDn3vP-FBmQ.png\"> <br/>\n",
    "<a href=\"https://arxiv.org/abs/2308.09687\">Source: Graph of Thoughts</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
    "\n",
    "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
    "\n",
    "A: Aristotle\n",
    "B: John Locke\n",
    "C: Socrates\n",
    "D: Plato\n",
    "\n",
    "Answer: Let's think step-by-step. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Answer the following multiple choice question by giving the most appropriate response. Answer should be one among [A, B, C, D].\n",
      "\n",
      "Question: The famous statement “An unexamined life is not worth living” is attributed to _____.\n",
      "\n",
      "A: Aristotle\n",
      "B: John Locke\n",
      "C: Socrates\n",
      "D: Plato\n",
      "\n",
      "Answer: Let's think step-by-step.  The quote is attributed to Socrates.  Socrates was a Greek philosopher who lived in ancient Athens.  He is known for his method of questioning, which is now called the Socratic method.  Socrates believed that the unexamined life is not worth living, and this quote reflects his belief that one must examine their own life and values in order to live a meaningful and fulfilling life.  Therefore, the correct answer is C.  The other options are incorrect because Aristotle was a philosopher\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "\n",
    "model_output_tokens = model.generate(\n",
    "    prompt_tokens, do_sample=False, temperature=None, max_new_tokens=100,\n",
    "    pad_token_id=tokenizer.eos_token_id, attention_mask=torch.ones_like(prompt_tokens)\n",
    ").squeeze(0)\n",
    "model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "print(model_output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From next-token predictions to a chatbot\n",
    "\n",
    "+ Now that we can generate continuations of sequences, what if we want to chat with the LLM as an assistant or chatbot?\n",
    "+ We can't just query it as we were doing before ❌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|>What food do you recommend me? I'm looking for something that's easy to make\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_str = 'What food do you recommend me?'\n",
    "prompt_tokens = tokenizer.encode(prompt_str, add_special_tokens=True, return_tensors='pt').to('mps')\n",
    "model_output_tokens = model.generate(\n",
    "    prompt_tokens, do_sample=False, temperature=None, max_new_tokens=10,\n",
    "    pad_token_id=tokenizer.eos_token_id, attention_mask=torch.ones_like(prompt_tokens)\n",
    ").squeeze(0)\n",
    "model_output_str = tokenizer.decode(model_output_tokens.tolist())\n",
    "model_output_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to use a special **chat prompt template** that the model has been trained with on other chat data. These usually separate the text into `system`, `user`, and `assistant` roles and formats them back into a standardized sequence of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 198, 15724, 2696, 25, 220, 1032, 4723, 220, 2366, 19, 271, 2675, 527, 264, 11190, 18328, 13, 128009, 128006, 882, 128007, 271, 3923, 3691, 656, 499, 7079, 757, 30, 128009, 128006, 78191, 128007, 271]]\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 13 Nov 2024\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What food do you recommend me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "  {\"role\": \"user\", \"content\": \"What food do you recommend me?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(prompt, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True,).to(device)\n",
    "print(inputs['input_ids'].tolist()); print()\n",
    "print(tokenizer.decode(inputs['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's run the generation on this input and look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 13 Nov 2024\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What food do you recommend me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'd be happy to recommend some delicious food options for you. Since I don't know your personal preferences, I'll suggest a variety of cuisines and dishes that are popular and tasty.\n",
      "\n",
      "Here are a few ideas:\n",
      "\n",
      "1. **Italian**: Try a classic pasta dish like spaghetti carbonara, pizza\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs, do_sample=False, temperature=None,\n",
    "    max_new_tokens=60, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code generation\n",
    "\n",
    "Lastly, let's switch to some basic code generation with Code Llama. We will load a quantized version for speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e8034a81384b01821ff05d1f9253b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8740af34875f475d9e0e9cb96860eff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "del tokenizer # now is inside the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/CodeLlama-7B-GGUF\", model_file=\"codellama-7b.Q2_K.gguf\", model_type=\"llama\", gpu_layers=0,\n",
    "    max_new_tokens=50, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(top_k=40, top_p=0.95, temperature=0.1, repetition_penalty=1.1, last_n_tokens=64, seed=-1, batch_size=8, threads=-1, max_new_tokens=50, stop=None, stream=False, reset=True, context_length=-1, gpu_layers=0, mmap=True, mlock=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For simple completions, the prompt can be the same as before with the start of a block of code.\n",
    "This is an example from the standard [humanevalplus](https://huggingface.co/datasets/evalplus/humanevalplus)\n",
    "dataset and benchmark. We can look at the tokenization in the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 29871, 13, 1753, 18755, 29898, 29876, 29901, 938, 1125, 13, 1678, 9995, 11609, 302, 29899, 386, 383, 747, 265, 21566, 1353, 29889, 13, 1678, 8653, 18755, 29898, 29896, 29900, 29897, 13, 268, 29945, 29945, 13, 1678, 8653, 18755, 29898, 29896, 29897, 13, 268, 29896, 13, 1678, 8653, 18755, 29898, 29947, 29897, 13, 268, 29906, 29896, 13, 1678, 9995, 13]\n"
     ]
    }
   ],
   "source": [
    "prompt_str = '''\n",
    "def fib(n: int):\n",
    "    \"\"\"Return n-th Fibonacci number.\n",
    "    >>> fib(10)\n",
    "    55\n",
    "    >>> fib(1)\n",
    "    1\n",
    "    >>> fib(8)\n",
    "    21\n",
    "    \"\"\"\n",
    "'''\n",
    "print(model.tokenize(prompt_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And query the model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    if n < 2:\n",
      "        return n\n",
      "    else:\n",
      "        return fib(n-1) + fib(n-2)\n",
      "\n",
      "def test_fib():\n",
      "    assert fib(1) == 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model(prompt_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From code completion to infilling\n",
    "\n",
    "+ Completion works great and is powerful, but what if we want to generate suggestions in the middle of a larger file?\n",
    "+ **How do we prompt the model in the middle of the code??**\n",
    "\n",
    "---\n",
    "\n",
    "```Python\n",
    "def fib(n: int):\n",
    "    \"\"\"Return n-th Fibonacci number.\n",
    "    >>> fib(10)\n",
    "    55\n",
    "    >>> fib(1)\n",
    "    1\n",
    "    >>> fib(8)\n",
    "    21\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        <<<user's cursor is here>>>\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Infilling and fill-in-the-middle (FIM) prompting\n",
    "\n",
    "+ Think about the file consisting of `PREFIX`, `MIDDLE`, and `SUFFIX` portions\n",
    "+ **Key idea:** reformulate the prompt so the middle comes at the end,\n",
    "  so a file is represented as `<PRE> prefix <SUF>suffix <MID>middle`\n",
    "  + This uses special tokens `<PRE>` `<MID>` and `<SUF>` to separate them\n",
    "  + ⚠ **Need to be very careful with the spaces**\n",
    "+ More details in [Efficient Training of Language Models to Fill in the Middle](https://arxiv.org/abs/2207.14255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's what the basic FIM prompt tokenizes to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 32007, 775, 32008, 401, 32009]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenize('<PRE> code <SUF>code <MID>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can put the Fibonacci prompt into this format and ask for the middle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return n <EOT>\n"
     ]
    }
   ],
   "source": [
    "prompt_str = '''<PRE> def fib(n: int):\n",
    "    \"\"\"Return n-th Fibonacci number.\n",
    "    >>> fib(10)\n",
    "    55\n",
    "    >>> fib(1)\n",
    "    1\n",
    "    >>> fib(8)\n",
    "    21\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "         <SUF>\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2) <MID>'''\n",
    "print(model(prompt_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<left><img width=25% src=\"img/cornell_tech2.svg\"></left>\n",
    "\n",
    "# Summary\n",
    "1. Tour through my favorite introductory parts from them\n",
    "2. Some code examples to show how to apply and use <br/>\n",
    "    a) **basic tokenization** and **autoregressive generation**, <br/>\n",
    "    b) **chat templates**, and <br/>\n",
    "    c) **code completion** (fill-in-the-middle)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "neural-ode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "rise": {
   "controlsTutorial": false,
   "height": 900,
   "help": false,
   "margin": 0,
   "maxScale": 2,
   "minScale": 0.2,
   "progress": true,
   "scroll": true,
   "theme": "simple",
   "width": 1200
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
